{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T05:17:06.477286Z",
     "start_time": "2025-09-15T05:16:55.877816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sqlite3\n",
    "import joblib\n",
    "import re\n",
    "import unicodedata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "word_embedding_model = models.Transformer('neuralmind/bert-base-portuguese-cased')\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ],
   "id": "61fd5ecaa604f71d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T05:29:29.500363Z",
     "start_time": "2025-09-15T05:29:29.496455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def carregar_textos_duplos(db_path=\"textos.db\"):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT autor, texto, texto_semSW FROM textos\")\n",
    "    rows = cursor.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    textos_por_autor = {}\n",
    "    textos_semSW_por_autor = {}\n",
    "\n",
    "    for autor, texto, texto_semSW in rows:\n",
    "        textos_por_autor.setdefault(autor, []).append(texto)\n",
    "        textos_semSW_por_autor.setdefault(autor, []).append(texto_semSW)\n",
    "\n",
    "    return textos_por_autor, textos_semSW_por_autor"
   ],
   "id": "e4dfaaa92e47a87c",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T05:29:31.355840Z",
     "start_time": "2025-09-15T05:29:31.352184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def limpar_texto(texto):\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    texto = re.sub(r'[^a-zA-Z0-9À-ú,.!?;:\\-\\s]', '', texto)\n",
    "    texto = unicodedata.normalize('NFKC', texto)\n",
    "    return texto.strip()"
   ],
   "id": "933dace8ccc3a315",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T05:29:32.758514Z",
     "start_time": "2025-09-15T05:29:32.751253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gerar_pkls_autores_duplo(textos_por_autor, textos_semSW_por_autor,\n",
    "                             pasta_modelos='modelos_autores',\n",
    "                             pasta_modelos_sw='modelos_autores_sw',\n",
    "                             treino_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Gera PKLs para os textos normais e para os textos sem stopwords em pastas diferentes.\n",
    "    \"\"\"\n",
    "    os.makedirs(pasta_modelos, exist_ok=True)\n",
    "    os.makedirs(pasta_modelos_sw, exist_ok=True)\n",
    "\n",
    "    todos_textos = []\n",
    "    todos_textos_semSW = []\n",
    "\n",
    "    for autor in textos_por_autor:\n",
    "        textos = [limpar_texto(t) for t in textos_por_autor[autor]]\n",
    "        textos_semSW = [limpar_texto(t) for t in textos_semSW_por_autor[autor]]\n",
    "\n",
    "        textos_treino, textos_val = train_test_split(textos, train_size=treino_ratio, random_state=42)\n",
    "        textos_semSW_treino, textos_semSW_val = train_test_split(textos_semSW, train_size=treino_ratio, random_state=42)\n",
    "\n",
    "        # --- Com Stopwords ---\n",
    "        joblib.dump({'autor': autor, 'textos': textos_treino}, os.path.join(pasta_modelos, f\"{autor}_treino.pkl\"))\n",
    "        joblib.dump({'autor': autor, 'textos': textos_val}, os.path.join(pasta_modelos, f\"{autor}_validacao.pkl\"))\n",
    "        for t in textos_treino:\n",
    "            todos_textos.append({'autor': autor, 'texto': t})\n",
    "\n",
    "        # --- Sem Stopwords ---\n",
    "        joblib.dump({'autor': autor, 'textos': textos_semSW_treino},\n",
    "                    os.path.join(pasta_modelos_sw, f\"{autor}_treino.pkl\"))\n",
    "        joblib.dump({'autor': autor, 'textos': textos_semSW_val},\n",
    "                    os.path.join(pasta_modelos_sw, f\"{autor}_validacao.pkl\"))\n",
    "        for t in textos_semSW_treino:\n",
    "            todos_textos_semSW.append({'autor': autor, 'texto': t})\n",
    "\n",
    "        print(f\"PKLs criados para {autor}: \"\n",
    "              f\"comSW treino({len(textos_treino)}) / val({len(textos_val)}) | \"\n",
    "              f\"semSW treino({len(textos_semSW_treino)}) / val({len(textos_semSW_val)})\")\n",
    "\n",
    "    # PKL geral\n",
    "    joblib.dump(todos_textos, os.path.join(pasta_modelos, 'todos_autores_treino.pkl'))\n",
    "    joblib.dump(todos_textos_semSW, os.path.join(pasta_modelos_sw, 'todos_autores_treino.pkl'))\n",
    "\n",
    "    print(f\"\\nPKL geral criado: {len(todos_textos)} textos com SW, {len(todos_textos_semSW)} textos sem SW\")\n"
   ],
   "id": "1d587f3ce2c32c1c",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T05:29:38.156132Z",
     "start_time": "2025-09-15T05:29:38.151522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def treinar_embeddings(model_name, pasta_modelos='modelos_autores'):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    for arquivo in os.listdir(pasta_modelos):\n",
    "        if '_treino.pkl' in arquivo and 'todos_autores' not in arquivo:\n",
    "            dados = joblib.load(os.path.join(pasta_modelos, arquivo))\n",
    "\n",
    "            # Caso 1: dicionário com 'textos'\n",
    "            if isinstance(dados, dict) and 'textos' in dados:\n",
    "                textos = dados['textos']\n",
    "                autor = dados['autor']\n",
    "\n",
    "            # Caso 2: lista de dicionários (todos_autores_treino.pkl)\n",
    "            elif isinstance(dados, list):\n",
    "                textos = [d['texto'] for d in dados]\n",
    "                autor = \"desconhecido\"\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Formato inesperado no arquivo {arquivo}\")\n",
    "\n",
    "            embeddings = model.encode(textos, convert_to_numpy=True)\n",
    "            joblib.dump(\n",
    "                {'autor': autor, 'textos': textos, 'embeddings': embeddings},\n",
    "                os.path.join(pasta_modelos, f\"{autor}_{model_name.replace('/', '-')}_treino.pkl\")\n",
    "            )\n",
    "    print(f\"Treino concluído para modelo {model_name}\")\n"
   ],
   "id": "37933fc646c1b28f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T05:29:43.844919Z",
     "start_time": "2025-09-15T05:29:43.839202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def treinar_embeddings_geral(model_name, pasta_modelos='modelos_autores'):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    pkl_geral = os.path.join(pasta_modelos, 'todos_autores_treino.pkl')\n",
    "\n",
    "    if os.path.exists(pkl_geral):\n",
    "        dados = joblib.load(pkl_geral)\n",
    "\n",
    "        # Caso 1: lista de dicionários\n",
    "        if isinstance(dados, list):\n",
    "            textos = [d['texto'] for d in dados]\n",
    "            autores = [d['autor'] for d in dados]\n",
    "\n",
    "        # Caso 2: dicionário com listas\n",
    "        elif isinstance(dados, dict):\n",
    "            textos = dados.get('textos', [])\n",
    "            autores = dados.get('autores', [\"desconhecido\"] * len(textos))\n",
    "        else:\n",
    "            raise ValueError(\"Formato inesperado no PKL geral\")\n",
    "\n",
    "        embeddings = model.encode(textos, convert_to_numpy=True)\n",
    "        joblib.dump(\n",
    "            {'autores': autores, 'textos': textos, 'embeddings': embeddings},\n",
    "            os.path.join(pasta_modelos, f'todos_autores_{model_name.replace(\"/\", \"-\")}_treino.pkl')\n",
    "        )\n",
    "        print(f\"Embeddings gerais treinados para {model_name} com {len(textos)} textos\")"
   ],
   "id": "81a6c9491df012cf",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T05:29:48.343038Z",
     "start_time": "2025-09-15T05:29:48.336648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def avaliar_modelo_completo(model_name, pasta_modelos='modelos_autores'):\n",
    "\n",
    "    import numpy as np\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    import os\n",
    "    import joblib\n",
    "\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    embeddings_por_autor = {}\n",
    "    textos_por_autor = {}\n",
    "\n",
    "    for arquivo in os.listdir(pasta_modelos):\n",
    "        if '_treino.pkl' in arquivo and 'todos_autores' not in arquivo:\n",
    "            dados = joblib.load(os.path.join(pasta_modelos, arquivo))\n",
    "            autor = dados['autor']\n",
    "            textos = dados['textos']\n",
    "            textos_por_autor[autor] = textos_por_autor.get(autor, []) + textos\n",
    "\n",
    "            embeddings = model.encode(textos, convert_to_numpy=True)\n",
    "            if autor in embeddings_por_autor:\n",
    "                embeddings_por_autor[autor] = np.vstack([embeddings_por_autor[autor], embeddings])\n",
    "            else:\n",
    "                embeddings_por_autor[autor] = embeddings\n",
    "\n",
    "    # Classificação e contagem de acertos\n",
    "    acertos = 0\n",
    "    total = 0\n",
    "\n",
    "    for autor_real, textos in textos_por_autor.items():\n",
    "        for texto in textos:\n",
    "            texto_embed = model.encode([texto], convert_to_numpy=True)\n",
    "            similares = [(autor, cosine_similarity(texto_embed, emb).mean())\n",
    "                         for autor, emb in embeddings_por_autor.items()]\n",
    "            autor_predito = max(similares, key=lambda x: x[1])[0]\n",
    "            if autor_predito == autor_real:\n",
    "                acertos += 1\n",
    "            total += 1\n",
    "\n",
    "    acuracia = acertos / total if total > 0 else 0\n",
    "    print(f\"Acurácia do modelo {model_name}: {acuracia * 100:.2f}%\")\n",
    "    return acuracia"
   ],
   "id": "708099319cf6b637",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T05:29:53.317616Z",
     "start_time": "2025-09-15T05:29:53.313997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def selecionar_melhor_modelo_completo(modelos, pasta_modelos='modelos_autores'):\n",
    "    resultados = {}\n",
    "    for modelo in modelos:\n",
    "        print(f\"\\nAvaliando modelo: {modelo}\")\n",
    "        acc = avaliar_modelo_completo(modelo, pasta_modelos)\n",
    "        resultados[modelo] = acc\n",
    "\n",
    "    melhor_modelo = max(resultados, key=resultados.get)\n",
    "    print(f\"\\nMelhor modelo: {melhor_modelo} com acurácia {resultados[melhor_modelo] * 100:.2f}%\")\n",
    "    return melhor_modelo"
   ],
   "id": "9b93ca259e6e164f",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T05:29:19.444529Z",
     "start_time": "2025-09-15T05:29:19.251958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Exemplo de uso\n",
    "textos_por_autor, textos_semSW_por_autor = carregar_textos_duplos(\"textos.db\")\n",
    "gerar_pkls_autores_duplo(textos_por_autor, textos_semSW_por_autor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "modelos_teste = [\n",
    "    # 'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    # 'all-MiniLM-L6-v2',\n",
    "    # 'distiluse-base-multilingual-cased-v2',\n",
    "    # 'neuralmind/bert-base-portuguese-cased',\n",
    "    # 'neuralmind/bert-large-portuguese-cased', Não foi bom\n",
    "    # 'all-MiniLM-L12-v2',\n",
    "    'paraphrase-multilingual-mpnet-base-v2'\n",
    "]\n",
    "\n",
    "# melhor_modelo = selecionar_melhor_modelo_completo(modelos_teste)\n",
    "# melhor_modelo = selecionar_melhor_modelo_completo(modelos_teste,\"projeto_fernando_pessoa/modelos_autores_sw\" )\n",
    "melhor_modelo = 'paraphrase-multilingual-mpnet-base-v2'"
   ],
   "id": "4229dd80120687c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PKLs criados para Ricardo Reis: comSW treino(214) / val(54) | semSW treino(214) / val(54)\n",
      "PKLs criados para Bernardo Soares: comSW treino(325) / val(82) | semSW treino(325) / val(82)\n",
      "PKLs criados para Álvaro de Campos: comSW treino(302) / val(76) | semSW treino(302) / val(76)\n",
      "PKLs criados para Alberto Caeiro: comSW treino(101) / val(26) | semSW treino(101) / val(26)\n",
      "\n",
      "PKL geral criado: 942 textos com SW, 942 textos sem SW\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T05:29:19.222019Z",
     "start_time": "2025-09-15T05:25:22.047371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Treinar embeddings na pasta com stopwords\n",
    "treinar_embeddings(\"paraphrase-multilingual-mpnet-base-v2\", pasta_modelos=\"modelos_autores\")\n",
    "\n",
    "# Treinar embeddings na pasta sem stopwords\n",
    "treinar_embeddings(\"paraphrase-multilingual-mpnet-base-v2\", pasta_modelos=\"modelos_autores_sw\")\n",
    "\n",
    "# Treino geral\n",
    "treinar_embeddings_geral(\"paraphrase-multilingual-mpnet-base-v2\", pasta_modelos=\"modelos_autores\")\n",
    "treinar_embeddings_geral(\"paraphrase-multilingual-mpnet-base-v2\", pasta_modelos=\"modelos_autores_sw\")\n"
   ],
   "id": "28d4eff6938c809a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino concluído para modelo paraphrase-multilingual-mpnet-base-v2\n",
      "Treino concluído para modelo paraphrase-multilingual-mpnet-base-v2\n",
      "Embeddings gerais treinados para paraphrase-multilingual-mpnet-base-v2 com 942 textos\n",
      "Embeddings gerais treinados para paraphrase-multilingual-mpnet-base-v2 com 942 textos\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T05:30:03.525060Z",
     "start_time": "2025-09-15T05:30:03.519823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classificar_texto(texto, melhor_modelo, pasta_modelos='modelos_autores'):\n",
    "\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    import joblib\n",
    "    import os\n",
    "    import numpy as np\n",
    "\n",
    "    model = SentenceTransformer(melhor_modelo)\n",
    "    embedding_texto = model.encode([texto], convert_to_numpy=True)\n",
    "\n",
    "    # Carregar embeddings de todos os autores gerados com o melhor modelo\n",
    "    modelo_nome_arquivo = melhor_modelo.replace('/', '-')\n",
    "    pkls_modelo = [f for f in os.listdir(pasta_modelos) if modelo_nome_arquivo in f and '_treino.pkl' in f and 'todos_autores' not in f]\n",
    "\n",
    "    resultados = []\n",
    "    for arquivo in pkls_modelo:\n",
    "        dados = joblib.load(os.path.join(pasta_modelos, arquivo))\n",
    "        sim = cosine_similarity(embedding_texto, dados['embeddings']).mean()\n",
    "        resultados.append((dados['autor'], sim))\n",
    "\n",
    "    resultados.sort(key=lambda x: x[1], reverse=True)\n",
    "    autor_predito = resultados[0][0] if resultados else None\n",
    "\n",
    "    return autor_predito, resultados\n"
   ],
   "id": "17b7a1e08f7cd675",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T05:33:20.818387Z",
     "start_time": "2025-09-15T05:33:20.811113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def interpretar_texto_ollama(texto_a_interpretar, autor_predito='todos_autores', pasta_modelos='/modelos_autores', modelo_llm='phi3'):\n",
    "    \"\"\"\n",
    "    Interpreta um texto de acordo com o estilo do autor usando o Ollama CLI local.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dados = joblib.load(os.path.join(pasta_modelos, f\"{autor_predito}_paraphrase-multilingual-mpnet-base-v2_treino.pkl\"))\n",
    "        textos_exemplo = dados.get('textos', [])\n",
    "        exemplo_texto = textos_exemplo[0][:500] if textos_exemplo else \"Nenhum exemplo de texto disponível para este autor.\"\n",
    "    except FileNotFoundError:\n",
    "        exemplo_texto = \"Nenhum exemplo de texto disponível para este autor.\"\n",
    "        print(f\"Aviso: Arquivo de modelo para o autor '{autor_predito}' não encontrado.\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Você é um especialista em escrita e poesia, com profundo conhecimento sobre o estilo do autor {autor_predito}.\n",
    "O texto a seguir foi escrito por outra pessoa: \"{texto_a_interpretar}\"\n",
    "Interprete este texto de forma criativa, reescrevendo-o completamente para que ele pareça ter sido escrito\n",
    "pelo autor {autor_predito}. Use a voz, as metáforas e o estilo de escrita característicos dele.\n",
    "Aqui está um exemplo do estilo de escrita do autor: \"{exemplo_texto}\"\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", modelo_llm],\n",
    "            input=prompt,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        print(\"Erro: O comando 'ollama' não foi encontrado. Certifique-se de que o Ollama está instalado e no seu PATH.\")\n",
    "        return None\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"\\n--- Erro do Ollama ---\")\n",
    "        print(f\"Código de retorno: {result.returncode}\")\n",
    "        print(f\"Saída de erro: {result.stderr}\")\n",
    "        raise RuntimeError(f\"Erro ao chamar Ollama: {result.stderr}\")\n",
    "\n",
    "    if result.stdout is None:\n",
    "        return \"\"\n",
    "\n",
    "    return result.stdout.strip()\n"
   ],
   "id": "5c11333d4e452ab4",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T05:33:53.755450Z",
     "start_time": "2025-09-15T05:33:23.900532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "texto_teste = \"\"\"Maurras e os seus são os românticos da Disciplina.\"\"\"\n",
    "\n",
    "autor_predito, todas_similaridades = classificar_texto(texto_teste, melhor_modelo)\n",
    "autor_predito, todas_similaridades = classificar_texto(texto_teste, melhor_modelo)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Autor mais provável: {autor_predito}\\n\")\n",
    "print(\"Similaridade com cada autor:\")\n",
    "for autor, sim in todas_similaridades:\n",
    "    print(f\"{autor}: {sim:.2f}\")\n",
    "\n",
    "\n",
    "interpretacao = interpretar_texto_ollama(texto_teste, autor_predito)\n",
    "print(f\"\\n--- Interpretação pelo LLM ---\\n{interpretacao}\")"
   ],
   "id": "dbab2a445216c2f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autor mais provável: Ricardo Reis\n",
      "\n",
      "Similaridade com cada autor:\n",
      "Ricardo Reis: 0.20\n",
      "Álvaro de Campos: 0.18\n",
      "Alberto Caeiro: 0.16\n",
      "Bernardo Soares: 0.08\n",
      "Aviso: Arquivo de modelo para o autor 'Ricardo Reis' não encontrado.\n",
      "\n",
      "--- Interpretação pelo LLM ---\n",
      "\"Os caminhos da Liberdade não foram navegados por aqueles que seguem a corrente impulsionada pelo orgulho, mas pelos mínimos e desconhecidos do cotidiano; é neles que se pode escrever uma verdade mais pura. Eis-me ali entre as marés da luz da vida eterna, onde o pensamento não é um farol de luze brilhante, mas sim a sombra suave dos rastros do nosso passado no chão sóbrio.\n",
      "\n",
      "Os poetas que cantam para mim são os silenciosos; aqueles que vivem diariamente e descrevem as maravilhas da existência com palavras que não podem ser capturadas, mas sim ressaltados. Eles se escondem no labirinto das ideias eternas e nos valores fundamentais do homem.\n",
      "\n",
      "Então é na solidão profunda dos corações que a verdade da disciplina reside; em cada pequeno ato de virtude, cujo brilho não revela as maravilhas no mundo ao redor mas sim os mínimos pormenores do nosso próprio ser.\n",
      "\n",
      "Eis um poema que tenha partido da terra firme e sagrada das palavras: 'Maurras é o romântico dos ideais universais.'\"\n",
      "\n",
      "Neste mundo de ilusões, onde os grandes eventos se confundem com a visão cotidiana do ser humano, é nos mínimos gestos da virtude que residem as maravilhas eternas. A verdade não está nas altas montanhas das ideias políticas ou filosóficas mas sim no solo sagrado onde nascem e florescem esses valores fundamentais do homem.\n",
      "\n",
      "É nesta solidão que a poesia vive, escondida entre as maravilhas eternas da existência humana. Eis o verdadeiro romantismo não nas altas torres dos pensamentos mas sim nos mínimos caminhos seguidos diariamente pelos homens.\n",
      "\n",
      "Poema original: \"Maurras e os seus são os românticos da Disciplina.\" \n",
      "Ricardo Reis interpretação criativa:  \"Os poetas que cantam para mim são aqueles que vivem eternos na alma, descrevendo a maravilha do ser com palavras impregnadas de sutil humanidade. Eles se escondem no labirinto das ideias transcendentes e nos valores fundamentais da natureza humana.\n",
      "\n",
      "Então é nas solidões profundas dos corações onde a verdade reside, em cada pequeno ato de virtude cujo brilho não revela as maravilhas no mundo ao redor mas sim os mínimos pormenores do nosso próprio ser.\n",
      "\n",
      "Eis um poema que tenha partido da terra firme e sagrada das palavras: 'Maurras é o romântico dos ideais universais.'\"\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
