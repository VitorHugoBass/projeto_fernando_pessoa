{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T16:53:06.071996Z",
     "start_time": "2025-09-15T16:52:58.276819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sqlite3\n",
    "import joblib\n",
    "import re\n",
    "import unicodedata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "word_embedding_model = models.Transformer('neuralmind/bert-base-portuguese-cased')\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ],
   "id": "61fd5ecaa604f71d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vitor\\.conda\\envs\\projeto_fernando_pessoa\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T16:53:06.086364Z",
     "start_time": "2025-09-15T16:53:06.083137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def carregar_textos_duplos(db_path=\"textos.db\"):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT autor, texto, texto_semSW FROM textos\")\n",
    "    rows = cursor.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    textos_por_autor = {}\n",
    "    textos_semSW_por_autor = {}\n",
    "\n",
    "    for autor, texto, texto_semSW in rows:\n",
    "        textos_por_autor.setdefault(autor, []).append(texto)\n",
    "        textos_semSW_por_autor.setdefault(autor, []).append(texto_semSW)\n",
    "\n",
    "    return textos_por_autor, textos_semSW_por_autor"
   ],
   "id": "e4dfaaa92e47a87c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T16:53:06.095685Z",
     "start_time": "2025-09-15T16:53:06.093190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def limpar_texto(texto):\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    texto = re.sub(r'[^a-zA-Z0-9À-ú,.!?;:\\-\\s]', '', texto)\n",
    "    texto = unicodedata.normalize('NFKC', texto)\n",
    "    return texto.strip()"
   ],
   "id": "933dace8ccc3a315",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T16:53:06.108645Z",
     "start_time": "2025-09-15T16:53:06.103712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gerar_pkls_autores_duplo(textos_por_autor, textos_semSW_por_autor,\n",
    "                             pasta_modelos='modelos_autores',\n",
    "                             pasta_modelos_sw='modelos_autores_sw',\n",
    "                             treino_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Gera PKLs para os textos normais e para os textos sem stopwords em pastas diferentes.\n",
    "    \"\"\"\n",
    "    os.makedirs(pasta_modelos, exist_ok=True)\n",
    "    os.makedirs(pasta_modelos_sw, exist_ok=True)\n",
    "\n",
    "    todos_textos = []\n",
    "    todos_textos_semSW = []\n",
    "\n",
    "    for autor in textos_por_autor:\n",
    "        textos = [limpar_texto(t) for t in textos_por_autor[autor]]\n",
    "        textos_semSW = [limpar_texto(t) for t in textos_semSW_por_autor[autor]]\n",
    "\n",
    "        textos_treino, textos_val = train_test_split(textos, train_size=treino_ratio, random_state=42)\n",
    "        textos_semSW_treino, textos_semSW_val = train_test_split(textos_semSW, train_size=treino_ratio, random_state=42)\n",
    "\n",
    "        # --- Com Stopwords ---\n",
    "        joblib.dump({'autor': autor, 'textos': textos_treino}, os.path.join(pasta_modelos, f\"{autor}_treino.pkl\"))\n",
    "        joblib.dump({'autor': autor, 'textos': textos_val}, os.path.join(pasta_modelos, f\"{autor}_validacao.pkl\"))\n",
    "        for t in textos_treino:\n",
    "            todos_textos.append({'autor': autor, 'texto': t})\n",
    "\n",
    "        # --- Sem Stopwords ---\n",
    "        joblib.dump({'autor': autor, 'textos': textos_semSW_treino},\n",
    "                    os.path.join(pasta_modelos_sw, f\"{autor}_treino.pkl\"))\n",
    "        joblib.dump({'autor': autor, 'textos': textos_semSW_val},\n",
    "                    os.path.join(pasta_modelos_sw, f\"{autor}_validacao.pkl\"))\n",
    "        for t in textos_semSW_treino:\n",
    "            todos_textos_semSW.append({'autor': autor, 'texto': t})\n",
    "\n",
    "        print(f\"PKLs criados para {autor}: \"\n",
    "              f\"comSW treino({len(textos_treino)}) / val({len(textos_val)}) | \"\n",
    "              f\"semSW treino({len(textos_semSW_treino)}) / val({len(textos_semSW_val)})\")\n",
    "\n",
    "    # PKL geral\n",
    "    joblib.dump(todos_textos, os.path.join(pasta_modelos, 'todos_autores_treino.pkl'))\n",
    "    joblib.dump(todos_textos_semSW, os.path.join(pasta_modelos_sw, 'todos_autores_treino.pkl'))\n",
    "\n",
    "    print(f\"\\nPKL geral criado: {len(todos_textos)} textos com SW, {len(todos_textos_semSW)} textos sem SW\")\n"
   ],
   "id": "1d587f3ce2c32c1c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T16:53:09.289096Z",
     "start_time": "2025-09-15T16:53:09.285057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def treinar_embeddings(model_name, pasta_modelos='modelos_autores'):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    for arquivo in os.listdir(pasta_modelos):\n",
    "        if '_treino.pkl' in arquivo and 'todos_autores' not in arquivo:\n",
    "            dados = joblib.load(os.path.join(pasta_modelos, arquivo))\n",
    "\n",
    "            # Caso 1: dicionário com 'textos'\n",
    "            if isinstance(dados, dict) and 'textos' in dados:\n",
    "                textos = dados['textos']\n",
    "                autor = dados['autor']\n",
    "\n",
    "            # Caso 2: lista de dicionários (todos_autores_treino.pkl)\n",
    "            elif isinstance(dados, list):\n",
    "                textos = [d['texto'] for d in dados]\n",
    "                autor = \"desconhecido\"\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Formato inesperado no arquivo {arquivo}\")\n",
    "\n",
    "            embeddings = model.encode(textos, convert_to_numpy=True)\n",
    "            joblib.dump(\n",
    "                {'autor': autor, 'textos': textos, 'embeddings': embeddings},\n",
    "                os.path.join(pasta_modelos, f\"{autor}_{model_name.replace('/', '-')}_treino.pkl\")\n",
    "            )\n",
    "    print(f\"Treino concluído para modelo {model_name}\")\n"
   ],
   "id": "37933fc646c1b28f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T16:53:11.302191Z",
     "start_time": "2025-09-15T16:53:11.298234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def treinar_embeddings_geral(model_name, pasta_modelos='modelos_autores'):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    pkl_geral = os.path.join(pasta_modelos, 'todos_autores_treino.pkl')\n",
    "\n",
    "    if os.path.exists(pkl_geral):\n",
    "        dados = joblib.load(pkl_geral)\n",
    "\n",
    "        # Caso 1: lista de dicionários\n",
    "        if isinstance(dados, list):\n",
    "            textos = [d['texto'] for d in dados]\n",
    "            autores = [d['autor'] for d in dados]\n",
    "\n",
    "        # Caso 2: dicionário com listas\n",
    "        elif isinstance(dados, dict):\n",
    "            textos = dados.get('textos', [])\n",
    "            autores = dados.get('autores', [\"desconhecido\"] * len(textos))\n",
    "        else:\n",
    "            raise ValueError(\"Formato inesperado no PKL geral\")\n",
    "\n",
    "        embeddings = model.encode(textos, convert_to_numpy=True)\n",
    "        joblib.dump(\n",
    "            {'autores': autores, 'textos': textos, 'embeddings': embeddings},\n",
    "            os.path.join(pasta_modelos, f'todos_autores_{model_name.replace(\"/\", \"-\")}_treino.pkl')\n",
    "        )\n",
    "        print(f\"Embeddings gerais treinados para {model_name} com {len(textos)} textos\")"
   ],
   "id": "81a6c9491df012cf",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T16:53:12.755507Z",
     "start_time": "2025-09-15T16:53:12.750388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def avaliar_modelo_completo(model_name, pasta_modelos='modelos_autores'):\n",
    "\n",
    "    import numpy as np\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    import os\n",
    "    import joblib\n",
    "\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    embeddings_por_autor = {}\n",
    "    textos_por_autor = {}\n",
    "\n",
    "    for arquivo in os.listdir(pasta_modelos):\n",
    "        if '_treino.pkl' in arquivo and 'todos_autores' not in arquivo:\n",
    "            dados = joblib.load(os.path.join(pasta_modelos, arquivo))\n",
    "            autor = dados['autor']\n",
    "            textos = dados['textos']\n",
    "            textos_por_autor[autor] = textos_por_autor.get(autor, []) + textos\n",
    "\n",
    "            embeddings = model.encode(textos, convert_to_numpy=True)\n",
    "            if autor in embeddings_por_autor:\n",
    "                embeddings_por_autor[autor] = np.vstack([embeddings_por_autor[autor], embeddings])\n",
    "            else:\n",
    "                embeddings_por_autor[autor] = embeddings\n",
    "\n",
    "    # Classificação e contagem de acertos\n",
    "    acertos = 0\n",
    "    total = 0\n",
    "\n",
    "    for autor_real, textos in textos_por_autor.items():\n",
    "        for texto in textos:\n",
    "            texto_embed = model.encode([texto], convert_to_numpy=True)\n",
    "            similares = [(autor, cosine_similarity(texto_embed, emb).mean())\n",
    "                         for autor, emb in embeddings_por_autor.items()]\n",
    "            autor_predito = max(similares, key=lambda x: x[1])[0]\n",
    "            if autor_predito == autor_real:\n",
    "                acertos += 1\n",
    "            total += 1\n",
    "\n",
    "    acuracia = acertos / total if total > 0 else 0\n",
    "    print(f\"Acurácia do modelo {model_name}: {acuracia * 100:.2f}%\")\n",
    "    return acuracia"
   ],
   "id": "708099319cf6b637",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T16:53:15.765058Z",
     "start_time": "2025-09-15T16:53:15.761818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def selecionar_melhor_modelo_completo(modelos, pasta_modelos='modelos_autores'):\n",
    "    resultados = {}\n",
    "    for modelo in modelos:\n",
    "        print(f\"\\nAvaliando modelo: {modelo}\")\n",
    "        acc = avaliar_modelo_completo(modelo, pasta_modelos)\n",
    "        resultados[modelo] = acc\n",
    "\n",
    "    melhor_modelo = max(resultados, key=resultados.get)\n",
    "    print(f\"\\nMelhor modelo: {melhor_modelo} com acurácia {resultados[melhor_modelo] * 100:.2f}%\")\n",
    "    return melhor_modelo"
   ],
   "id": "9b93ca259e6e164f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T16:53:18.371039Z",
     "start_time": "2025-09-15T16:53:18.286603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Exemplo de uso\n",
    "textos_por_autor, textos_semSW_por_autor = carregar_textos_duplos(\"textos.db\")\n",
    "gerar_pkls_autores_duplo(textos_por_autor, textos_semSW_por_autor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "modelos_teste = [\n",
    "    # 'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    # 'all-MiniLM-L6-v2',\n",
    "    # 'distiluse-base-multilingual-cased-v2',\n",
    "    # 'neuralmind/bert-base-portuguese-cased',\n",
    "    # 'neuralmind/bert-large-portuguese-cased', Não foi bom\n",
    "    # 'all-MiniLM-L12-v2',\n",
    "    'paraphrase-multilingual-mpnet-base-v2'\n",
    "]\n",
    "\n",
    "# melhor_modelo = selecionar_melhor_modelo_completo(modelos_teste)\n",
    "# melhor_modelo = selecionar_melhor_modelo_completo(modelos_teste,\"projeto_fernando_pessoa/modelos_autores_sw\" )\n",
    "melhor_modelo = 'paraphrase-multilingual-mpnet-base-v2'"
   ],
   "id": "4229dd80120687c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PKLs criados para Ricardo Reis: comSW treino(214) / val(54) | semSW treino(214) / val(54)\n",
      "PKLs criados para Bernardo Soares: comSW treino(325) / val(82) | semSW treino(325) / val(82)\n",
      "PKLs criados para Álvaro de Campos: comSW treino(302) / val(76) | semSW treino(302) / val(76)\n",
      "PKLs criados para Alberto Caeiro: comSW treino(101) / val(26) | semSW treino(101) / val(26)\n",
      "\n",
      "PKL geral criado: 942 textos com SW, 942 textos sem SW\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T16:55:59.709917Z",
     "start_time": "2025-09-15T16:53:19.875827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Treinar embeddings na pasta com stopwords\n",
    "treinar_embeddings(\"paraphrase-multilingual-mpnet-base-v2\", pasta_modelos=\"modelos_autores\")\n",
    "\n",
    "# Treinar embeddings na pasta sem stopwords\n",
    "treinar_embeddings(\"paraphrase-multilingual-mpnet-base-v2\", pasta_modelos=\"modelos_autores_sw\")\n",
    "\n",
    "# Treino geral\n",
    "treinar_embeddings_geral(\"paraphrase-multilingual-mpnet-base-v2\", pasta_modelos=\"modelos_autores\")\n",
    "treinar_embeddings_geral(\"paraphrase-multilingual-mpnet-base-v2\", pasta_modelos=\"modelos_autores_sw\")\n"
   ],
   "id": "28d4eff6938c809a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino concluído para modelo paraphrase-multilingual-mpnet-base-v2\n",
      "Treino concluído para modelo paraphrase-multilingual-mpnet-base-v2\n",
      "Embeddings gerais treinados para paraphrase-multilingual-mpnet-base-v2 com 942 textos\n",
      "Embeddings gerais treinados para paraphrase-multilingual-mpnet-base-v2 com 942 textos\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T16:56:04.904017Z",
     "start_time": "2025-09-15T16:56:04.899516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classificar_texto(texto, melhor_modelo, pasta_modelos='modelos_autores'):\n",
    "\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    import joblib\n",
    "    import os\n",
    "    import numpy as np\n",
    "\n",
    "    model = SentenceTransformer(melhor_modelo)\n",
    "    embedding_texto = model.encode([texto], convert_to_numpy=True)\n",
    "\n",
    "    # Carregar embeddings de todos os autores gerados com o melhor modelo\n",
    "    modelo_nome_arquivo = melhor_modelo.replace('/', '-')\n",
    "    pkls_modelo = [f for f in os.listdir(pasta_modelos) if modelo_nome_arquivo in f and '_treino.pkl' in f and 'todos_autores' not in f]\n",
    "\n",
    "    resultados = []\n",
    "    for arquivo in pkls_modelo:\n",
    "        dados = joblib.load(os.path.join(pasta_modelos, arquivo))\n",
    "        sim = cosine_similarity(embedding_texto, dados['embeddings']).mean()\n",
    "        resultados.append((dados['autor'], sim))\n",
    "\n",
    "    resultados.sort(key=lambda x: x[1], reverse=True)\n",
    "    autor_predito = resultados[0][0] if resultados else None\n",
    "\n",
    "    return autor_predito, resultados\n"
   ],
   "id": "17b7a1e08f7cd675",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:39:36.062785Z",
     "start_time": "2025-09-15T18:39:35.998847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def interpretar_texto_ollama(texto_a_interpretar, autor_predito='todos_autores', pasta_modelos='modelos_autores_sw', modelo_llm='phi3'):\n",
    "    \"\"\"\n",
    "    Interpreta um texto de acordo com o estilo do autor usando o Ollama CLI local.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dados = joblib.load(os.path.join(pasta_modelos, f\"{autor_predito}_paraphrase-multilingual-mpnet-base-v2_treino.pkl\"))\n",
    "        textos_exemplo = dados.get('textos', [])\n",
    "        exemplo_texto = textos_exemplo[0][:500] if textos_exemplo else \"Nenhum exemplo de texto disponível para este autor.\"\n",
    "    except FileNotFoundError:\n",
    "        exemplo_texto = \"Nenhum exemplo de texto disponível para este autor.\"\n",
    "        print(f\"Aviso: Arquivo de modelo para o autor '{autor_predito}' não encontrado.\")\n",
    "\n",
    "    prompt = f\"\"\"Você é {autor_predito}. Reescreva o texto abaixo mantendo o sentido original.\n",
    "Responda em português.\n",
    "\n",
    "Texto: \"{texto_a_interpretar}\"\n",
    "Exemplo: \"{exemplo_texto}\"\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", modelo_llm],\n",
    "            input=prompt,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        print(\"Erro: O comando 'ollama' não foi encontrado. Certifique-se de que o Ollama está instalado e no seu PATH.\")\n",
    "        return None\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"\\n--- Erro do Ollama ---\")\n",
    "        print(f\"Código de retorno: {result.returncode}\")\n",
    "        print(f\"Saída de erro: {result.stderr}\")\n",
    "        raise RuntimeError(f\"Erro ao chamar Ollama: {result.stderr}\")\n",
    "\n",
    "    if result.stdout is None:\n",
    "        return \"\"\n",
    "\n",
    "    return result.stdout.strip()\n"
   ],
   "id": "5c11333d4e452ab4",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:39:47.226924Z",
     "start_time": "2025-09-15T18:39:39.835160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "texto_teste = \"\"\"No entardecer dos dias de Verão, às vezes,\n",
    "Ainda que não haja brisa nenhuma, parece\n",
    "Que passa, um momento, uma leve brisa...\n",
    "Mas as árvores permanecem imóveis.\"\"\"\n",
    "\n",
    "autor_predito, todas_similaridades = classificar_texto(texto_teste, melhor_modelo)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Autor mais provável: {autor_predito}\\n\")\n",
    "print(\"Similaridade com cada autor:\")\n",
    "for autor, sim in todas_similaridades:\n",
    "    print(f\"{autor}: {sim:.2f}\")\n",
    "\n",
    "\n",
    "interpretacao = interpretar_texto_ollama(texto_teste, autor_predito)\n",
    "print(f\"\\n--- Interpretação pelo LLM ---\\n{interpretacao}\")"
   ],
   "id": "dbab2a445216c2f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autor mais provável: Alberto Caeiro\n",
      "\n",
      "Similaridade com cada autor:\n",
      "Alberto Caeiro: 0.34\n",
      "Ricardo Reis: 0.33\n",
      "Bernardo Soares: 0.29\n",
      "Álvaro de Campos: 0.29\n",
      "\n",
      "--- Interpretação pelo LLM ---\n",
      "No amanhecer daquele calor intenso do Verão,\n",
      "Às vezes, mesmo sem uma breve brisa desfilar,  \n",
      "Parece que flui um murmúrio leve... mas as árvores têm sua eternidade imutável.\n"
     ]
    }
   ],
   "execution_count": 53
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
