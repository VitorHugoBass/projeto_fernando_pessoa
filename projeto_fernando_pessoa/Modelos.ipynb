{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T03:06:59.419887Z",
     "start_time": "2025-09-15T03:06:58.131407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import sqlite3\n",
    "import os\n",
    "import joblib\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "word_embedding_model = models.Transformer('neuralmind/bert-base-portuguese-cased')\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n"
   ],
   "id": "61fd5ecaa604f71d",
   "outputs": [],
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-15T03:12:44.176529Z",
     "start_time": "2025-09-15T03:12:44.172671Z"
    }
   },
   "source": [
    "def carregar_textos(db_path=\"projeto_fernando_pessoa/textos.db\"):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT autor, texto FROM textos\")\n",
    "    rows = cursor.fetchall()\n",
    "    conn.close()\n",
    "    textos_por_autor = {}\n",
    "    for autor, texto in rows:\n",
    "        textos_por_autor.setdefault(autor, []).append(texto)\n",
    "    return textos_por_autor"
   ],
   "outputs": [],
   "execution_count": 199
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T03:12:45.680273Z",
     "start_time": "2025-09-15T03:12:45.676661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def limpar_texto(texto):\n",
    "    # Remove múltiplos espaços\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    # Remove caracteres especiais\n",
    "    texto = re.sub(r'[^a-zA-Z0-9À-ú,.!?;:\\-\\s]', '', texto)\n",
    "    # Normaliza acentos\n",
    "    texto = unicodedata.normalize('NFKC', texto)\n",
    "    # Strip\n",
    "    return texto.strip()"
   ],
   "id": "24013764b246b0b6",
   "outputs": [],
   "execution_count": 200
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T03:13:31.464077Z",
     "start_time": "2025-09-15T03:13:31.458046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gerar_pkls_autores(textos_por_autor, pasta_modelos='modelos_autores', treino_ratio=0.8):\n",
    "    os.makedirs(pasta_modelos, exist_ok=True)\n",
    "\n",
    "    todos_textos = []\n",
    "    for autor, textos in textos_por_autor.items():\n",
    "        textos_limpos = [limpar_texto(t) for t in textos]\n",
    "        textos_treino, textos_val = train_test_split(textos_limpos, train_size=treino_ratio, random_state=42)\n",
    "\n",
    "        # PKL individual\n",
    "        joblib.dump({'autor': autor, 'textos': textos_treino}, os.path.join(pasta_modelos, f\"{autor}_treino.pkl\"))\n",
    "        joblib.dump({'autor': autor, 'textos': textos_val}, os.path.join(pasta_modelos, f\"{autor}_validacao.pkl\"))\n",
    "        print(f\"PKLs criados para {autor}: treino({len(textos_treino)}) / validação({len(textos_val)})\")\n",
    "\n",
    "        # Adiciona ao PKL geral\n",
    "        for t in textos_treino:\n",
    "            todos_textos.append({'autor': autor, 'texto': t})\n",
    "\n",
    "    # PKL geral com todos os textos de treino\n",
    "    joblib.dump(todos_textos, os.path.join(pasta_modelos, 'todos_autores_treino.pkl'))\n",
    "    print(f\"PKL geral com todos os autores criado: {len(todos_textos)} textos\")\n",
    "\n"
   ],
   "id": "10de6c01b0cf8b4d",
   "outputs": [],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T03:13:35.587564Z",
     "start_time": "2025-09-15T03:13:35.582966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def treinar_embeddings(model_name, pasta_modelos='modelos_autores'):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    for arquivo in os.listdir(pasta_modelos):\n",
    "        if '_treino.pkl' in arquivo:\n",
    "            dados = joblib.load(os.path.join(pasta_modelos, arquivo))\n",
    "            embeddings = model.encode(dados['textos'], convert_to_numpy=True)\n",
    "            joblib.dump({'autor': dados['autor'], 'textos': dados['textos'], 'embeddings': embeddings},\n",
    "                        os.path.join(pasta_modelos, f\"{dados['autor']}_{model_name.replace('/', '-')}_treino.pkl\"))\n",
    "    print(f\"Treino concluído para modelo {model_name}\")"
   ],
   "id": "d689342e5c585a35",
   "outputs": [],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T03:13:38.592058Z",
     "start_time": "2025-09-15T03:13:38.587678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def treinar_embeddings_geral(model_name, pasta_modelos='modelos_autores'):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    pkl_geral = os.path.join(pasta_modelos, 'todos_autores_treino.pkl')\n",
    "\n",
    "    if os.path.exists(pkl_geral):\n",
    "        todos_textos = joblib.load(pkl_geral)\n",
    "        textos = [t['texto'] for t in todos_textos]\n",
    "        autores = [t['autor'] for t in todos_textos]\n",
    "\n",
    "        embeddings = model.encode(textos, convert_to_numpy=True)\n",
    "        joblib.dump({'autores': autores, 'textos': textos, 'embeddings': embeddings},\n",
    "                    os.path.join(pasta_modelos, f'todos_autores_{model_name.replace(\"/\", \"-\")}_treino.pkl'))\n",
    "        print(f\"Embeddings gerais treinados para {model_name} com {len(textos)} textos\")\n"
   ],
   "id": "648c47441d393141",
   "outputs": [],
   "execution_count": 212
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T03:13:40.489755Z",
     "start_time": "2025-09-15T03:13:40.485599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classificar_texto_geral(texto, modelo_embedding, pasta_modelos='modelos_autores'):\n",
    "    model = SentenceTransformer(modelo_embedding)\n",
    "    embedding_texto = model.encode([texto], convert_to_numpy=True)\n",
    "\n",
    "    # Carrega embeddings do PKL geral\n",
    "    pkl_geral = os.path.join(pasta_modelos, f'todos_autores_{modelo_embedding.replace(\"/\", \"-\")}_treino.pkl')\n",
    "    dados = joblib.load(pkl_geral)\n",
    "\n",
    "    sim = cosine_similarity(embedding_texto, dados['embeddings']).flatten()\n",
    "    autor_predito = dados['autores'][sim.argmax()]\n",
    "\n",
    "    # Calcula similaridade média por autor (opcional)\n",
    "    resultados = {}\n",
    "    for a, s in zip(dados['autores'], sim):\n",
    "        resultados[a] = max(resultados.get(a, 0), s)\n",
    "\n",
    "    resultados = sorted(resultados.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return autor_predito, resultados\n"
   ],
   "id": "231d24253c170a7b",
   "outputs": [],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T03:13:42.534806Z",
     "start_time": "2025-09-15T03:13:42.527998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def avaliar_modelo_completo(model_name, pasta_modelos='modelos_autores'):\n",
    "\n",
    "    import numpy as np\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    import os\n",
    "    import joblib\n",
    "\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    embeddings_por_autor = {}\n",
    "    textos_por_autor = {}\n",
    "\n",
    "    for arquivo in os.listdir(pasta_modelos):\n",
    "        if '_treino.pkl' in arquivo and 'todos_autores' not in arquivo:\n",
    "            dados = joblib.load(os.path.join(pasta_modelos, arquivo))\n",
    "            autor = dados['autor']\n",
    "            textos = dados['textos']\n",
    "            textos_por_autor[autor] = textos_por_autor.get(autor, []) + textos\n",
    "\n",
    "            embeddings = model.encode(textos, convert_to_numpy=True)\n",
    "            if autor in embeddings_por_autor:\n",
    "                embeddings_por_autor[autor] = np.vstack([embeddings_por_autor[autor], embeddings])\n",
    "            else:\n",
    "                embeddings_por_autor[autor] = embeddings\n",
    "\n",
    "    # Classificação e contagem de acertos\n",
    "    acertos = 0\n",
    "    total = 0\n",
    "\n",
    "    for autor_real, textos in textos_por_autor.items():\n",
    "        for texto in textos:\n",
    "            texto_embed = model.encode([texto], convert_to_numpy=True)\n",
    "            similares = [(autor, cosine_similarity(texto_embed, emb).mean())\n",
    "                         for autor, emb in embeddings_por_autor.items()]\n",
    "            autor_predito = max(similares, key=lambda x: x[1])[0]\n",
    "            if autor_predito == autor_real:\n",
    "                acertos += 1\n",
    "            total += 1\n",
    "\n",
    "    acuracia = acertos / total if total > 0 else 0\n",
    "    print(f\"Acurácia do modelo {model_name}: {acuracia * 100:.2f}%\")\n",
    "    return acuracia"
   ],
   "id": "9d98796009cd2870",
   "outputs": [],
   "execution_count": 214
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T03:13:44.822022Z",
     "start_time": "2025-09-15T03:13:44.817806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def selecionar_melhor_modelo_completo(modelos, pasta_modelos='modelos_autores'):\n",
    "    resultados = {}\n",
    "    for modelo in modelos:\n",
    "        print(f\"\\nAvaliando modelo: {modelo}\")\n",
    "        acc = avaliar_modelo_completo(modelo, pasta_modelos)\n",
    "        resultados[modelo] = acc\n",
    "\n",
    "    melhor_modelo = max(resultados, key=resultados.get)\n",
    "    print(f\"\\nMelhor modelo: {melhor_modelo} com acurácia {resultados[melhor_modelo] * 100:.2f}%\")\n",
    "    return melhor_modelo"
   ],
   "id": "4002237798c19e1d",
   "outputs": [],
   "execution_count": 215
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-15T03:20:33.065514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Garantir que PKLs já foram criados\n",
    "textos_por_autor = carregar_textos(\"projeto_fernando_pessoa/textos.db\")\n",
    "gerar_pkls_autores(textos_por_autor)\n",
    "\n",
    "modelos_teste = [\n",
    "    # 'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    # 'all-MiniLM-L6-v2',\n",
    "    # 'distiluse-base-multilingual-cased-v2',\n",
    "    # 'neuralmind/bert-base-portuguese-cased',\n",
    "    'neuralmind/bert-large-portuguese-cased',\n",
    "    'all-MiniLM-L12-v2',\n",
    "    'paraphrase-multilingual-mpnet-base-v2'\n",
    "]\n",
    "\n",
    "melhor_modelo = selecionar_melhor_modelo_completo(modelos_teste)"
   ],
   "id": "b02a6df091933e4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PKLs criados para Ricardo Reis: treino(214) / validação(54)\n",
      "PKLs criados para Bernardo Soares: treino(325) / validação(82)\n",
      "PKLs criados para Álvaro de Campos: treino(302) / validação(76)\n",
      "PKLs criados para Alberto Caeiro: treino(101) / validação(26)\n",
      "PKL geral com todos os autores criado: 942 textos\n",
      "\n",
      "Avaliando modelo: paraphrase-multilingual-MiniLM-L12-v2\n",
      "Acurácia do modelo paraphrase-multilingual-MiniLM-L12-v2: 69.53%\n",
      "\n",
      "Avaliando modelo: all-MiniLM-L6-v2\n",
      "Acurácia do modelo all-MiniLM-L6-v2: 47.35%\n",
      "\n",
      "Avaliando modelo: distiluse-base-multilingual-cased-v2\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def classificar_texto(texto, melhor_modelo, pasta_modelos='modelos_autores'):\n",
    "    \"\"\"\n",
    "    Classifica um texto usando embeddings do melhor modelo.\n",
    "    Retorna o autor mais provável e a similaridade com todos os autores.\n",
    "    \"\"\"\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    import joblib\n",
    "    import os\n",
    "    import numpy as np\n",
    "\n",
    "    model = SentenceTransformer(melhor_modelo)\n",
    "    embedding_texto = model.encode([texto], convert_to_numpy=True)\n",
    "\n",
    "    # Carregar embeddings de todos os autores gerados com o melhor modelo\n",
    "    modelo_nome_arquivo = melhor_modelo.replace('/', '-')\n",
    "    pkls_modelo = [f for f in os.listdir(pasta_modelos) if modelo_nome_arquivo in f and '_treino.pkl' in f]\n",
    "\n",
    "    resultados = []\n",
    "    for arquivo in pkls_modelo:\n",
    "        dados = joblib.load(os.path.join(pasta_modelos, arquivo))\n",
    "        sim = cosine_similarity(embedding_texto, dados['embeddings']).mean()\n",
    "        resultados.append((dados['autor'], sim))\n",
    "\n",
    "    resultados.sort(key=lambda x: x[1], reverse=True)\n",
    "    autor_predito = resultados[0][0] if resultados else None\n",
    "\n",
    "    return autor_predito, resultados\n"
   ],
   "id": "83a1410663d2e8ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T02:22:45.195198Z",
     "start_time": "2025-09-15T02:22:45.189302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classificar_autor_com_similaridade(texto, pasta_modelos='modelos_autores', modelo_embedding='distiluse-base-multilingual-cased-v2'):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    import joblib\n",
    "    import os\n",
    "\n",
    "    model = SentenceTransformer(modelo_embedding)\n",
    "    embedding_texto = model.encode([texto], convert_to_numpy=True)\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    # Filtra apenas os PKLs que foram gerados com o mesmo modelo\n",
    "    modelo_nome_arquivo = modelo_embedding.replace('/', '-')\n",
    "    pkls_modelo = [f for f in os.listdir(pasta_modelos) if modelo_nome_arquivo in f and '_treino.pkl' in f]\n",
    "\n",
    "    for arquivo in pkls_modelo:\n",
    "        dados = joblib.load(os.path.join(pasta_modelos, arquivo))\n",
    "        sim = cosine_similarity(embedding_texto, dados['embeddings'])\n",
    "        sim_media = sim.mean()\n",
    "        resultados.append((dados['autor'], sim_media))\n",
    "\n",
    "    resultados.sort(key=lambda x: x[1], reverse=True)\n",
    "    autor_predito = resultados[0][0] if resultados else None\n",
    "    return autor_predito, resultados\n"
   ],
   "id": "1275d68c524a4aaa",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T02:19:49.228476Z",
     "start_time": "2025-09-15T02:19:49.222852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def interpretar_texto_ollama(texto_a_interpretar, autor_predito, pasta_modelos='modelos_autores', modelo_llm='phi3'):\n",
    "    \"\"\"\n",
    "    Interpreta um texto de acordo com o estilo do autor usando o Ollama CLI local.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dados = joblib.load(os.path.join(pasta_modelos, f\"{autor_predito}.pkl\"))\n",
    "        textos_exemplo = dados.get('textos', [])\n",
    "        exemplo_texto = textos_exemplo[0][:500] if textos_exemplo else \"Nenhum exemplo de texto disponível para este autor.\"\n",
    "    except FileNotFoundError:\n",
    "        exemplo_texto = \"Nenhum exemplo de texto disponível para este autor.\"\n",
    "        print(f\"Aviso: Arquivo de modelo para o autor '{autor_predito}' não encontrado.\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Você é um especialista em escrita e poesia, com profundo conhecimento sobre o estilo do autor {autor_predito}.\n",
    "O texto a seguir foi escrito por outra pessoa: \"{texto_a_interpretar}\"\n",
    "Interprete este texto de forma criativa, reescrevendo-o completamente para que ele pareça ter sido escrito\n",
    "pelo autor {autor_predito}. Use a voz, as metáforas e o estilo de escrita característicos dele.\n",
    "Aqui está um exemplo do estilo de escrita do autor: \"{exemplo_texto}\"\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", modelo_llm],\n",
    "            input=prompt,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        print(\"Erro: O comando 'ollama' não foi encontrado. Certifique-se de que o Ollama está instalado e no seu PATH.\")\n",
    "        return None\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"\\n--- Erro do Ollama ---\")\n",
    "        print(f\"Código de retorno: {result.returncode}\")\n",
    "        print(f\"Saída de erro: {result.stderr}\")\n",
    "        raise RuntimeError(f\"Erro ao chamar Ollama: {result.stderr}\")\n",
    "\n",
    "    if result.stdout is None:\n",
    "        return \"\"\n",
    "\n",
    "    return result.stdout.strip()\n"
   ],
   "id": "5c11333d4e452ab4",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T02:26:58.538954Z",
     "start_time": "2025-09-15T02:26:56.026579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "texto_teste = \"\"\"Mover-se é viver, dizer-se é sobreviver. Não há nada de real na vida que o não seja porque se descreveu bem. Os críticos da casa pequena soem apontar que tal poema, longamente ritmado, não quer, afinal, dizer senão que o dia está bom.\"\"\"\n",
    "\n",
    "# autor_predito, todas_similaridades = classificar_autor_com_similaridade(texto_teste)\n",
    "autor_predito, todas_similaridades = classificar_texto(texto_teste, melhor_modelo)\n",
    "# autor_predito, todas_similaridades = classificar_texto_geral(texto_teste, melhor_modelo)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Autor mais provável: {autor_predito}\\n\")\n",
    "print(\"Similaridade com cada autor:\")\n",
    "for autor, sim in todas_similaridades:\n",
    "    print(f\"{autor}: {sim:.2f}\")\n",
    "\n",
    "\n",
    "# interpretacao = interpretar_texto_ollama(texto_teste, autor_predito)\n",
    "# print(f\"\\n--- Interpretação pelo LLM ---\\n{interpretacao}\")"
   ],
   "id": "dbab2a445216c2f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autor mais provável: Alberto Caeiro\n",
      "\n",
      "Similaridade com cada autor:\n",
      "Alberto Caeiro: 0.27\n",
      "Ricardo Reis: 0.26\n",
      "Álvaro de Campos: 0.25\n",
      "Bernardo Soares: 0.13\n"
     ]
    }
   ],
   "execution_count": 116
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
